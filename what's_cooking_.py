# -*- coding: utf-8 -*-
"""What's Cooking?.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16z-nZrdJGsjn3h759-SxnYebaRFVB8DX

# ***What's Cooking***

## ***predict the category of a dish's cuisine given a list of its ingredients.***   
## ***categorization accuracy (the percent of dishes that you correctly classify).***
"""

#Upload the file to colabs

from google.colab import files


uploaded = files.upload()

from google.colab import files

uploadtest = files.upload()

uploaded

uploadtest

import pandas as pd
import numpy as np

df=pd.read_json("train.json")
print(df)
df.to_csv('train.csv')

df=pd.read_json("test.json")
print(df)
df.to_csv('test.csv')

train = pd.read_csv('train.csv')

test = pd.read_csv('test.csv')

train.head()

train.tail()

test.head()

train.cuisine.value_counts()

train.cuisine.unique()

train.cuisine.value_counts().shape

train.shape

train.ingredients.head()

train.ingredients[0]



train.columns

train.head()

train.duplicated().sum()

df = train.ingredients
df.head()

df = df.str.replace('[','').str.replace(']','')

df.head()

df=df.str.replace(" ","")
df.head()

df=df.str.replace("'"," ")
df.head()

df = df.str.replace(',','')
df.head()

train.ingredients = df

train.ingredients = df

train.info()

train['num_ingredients'] = train['ingredients'].apply(len)
train = train[train['num_ingredients'] > 1]
train

pd.get_dummies(train,columns='ingredients')

train.ingredients.head()

df.head()

??str

df.head()

df_train = train

train.ingredients.get_dummies()

data = train.ingredients

# new data frame with split value columns 
new = data.str.split(" ", n = 1, expand = True) 
  
# making seperate first name column from new data frame 
data["First Name"]= new[0] 
  
# making seperate last name column from new data frame 
data["Last Name"]= new[1]

for n in range(0,4):
  new = train.ingredients.str.split(" ", n, expand = True)
  for n in new:
    train['names'] = new[n]
  continue

train.head(20)

df = train.ingredients

df

df = df.str.replace('  ',',')

df.head()

df.index

for n in range(0,4):
  new = df.ingredients.str.split(" ", n, expand = True)
  train['names'] = new[n]
  continue

df = pd.DataFrame(df)

df

def split(x):
  for n in range(0,len(df)):
    new = df.ingredients[n].str.split()

split(df)

sd = df[0:10]

sd.drop('names',axis=1,inplace = True)

sd = sd.transpose()

sd[0].str.split()

# new data frame with split value columns 
new = sd["0"].str.split(" ", n = 1, expand = True) 
  
# making seperate first name column from new data frame 
data["First Name"]= new[0] 
  
# making seperate last name column from new data frame 
data["Last Name"]= new[1]



"""# ***Kaggle ***"""

# Import the required libraries 
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
import pandas as pd
import json

import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('ggplot')

#Upload the file to colabs

from google.colab import files


uploaded = files.upload()

#Upload the file to colabs

from google.colab import files


uploaded_train = files.upload()

uploaded_train

import pandas as pd
import numpy as np

train = pd.read_json('train (1).json')
test = pd.read_json('test (2).json')

train.head()

train['seperated_ingredients'] = train['ingredients'].apply(','.join)
test['seperated_ingredients'] = test['ingredients'].apply(','.join)

train.head()

train_df = train
test_df = test

print('Maximum Number of Ingredients in a Dish: ',train_df['ingredients'].str.len().max())
print('Minimum Number of Ingredients in a Dish: ',train_df['ingredients'].str.len().min())

plt.hist(train_df['ingredients'].str.len(),bins=max(train_df['ingredients'].str.len()),edgecolor='g')
plt.gcf().set_size_inches(16,8)
plt.title('Ingredients in a Dish Distribution')

sns.countplot(y='cuisine', data=train_df,palette=sns.color_palette('inferno',15))
plt.gcf().set_size_inches(15,10)
plt.title('Cuisine Distribution',size=20)

from sklearn.feature_extraction.text import CountVectorizer
vec = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)
counts = vec.fit_transform(train_df['seperated_ingredients']) 
count=dict(zip(vec.get_feature_names(), counts.sum(axis=0).tolist()[0]))
count=pd.DataFrame(list(count.items()),columns=['Ingredient','Count'])
count.set_index('Ingredient').sort_values('Count',ascending=False)[:15].plot.barh(width=0.9)
plt.gcf().set_size_inches(10,10)
plt.gca().invert_yaxis()
plt.title('Top 15 Ingredients')

count.shape

ingreList = []
for index, row in train_df.iterrows():
    ingre = row['ingredients']
    
    for i in ingre:
        if i not in ingreList:
            ingreList.append(i)
def binary(ingre_list):
    binaryList = []
    
    for item in ingreList:
        if item in ingre_list:
            binaryList.append(1)
        else:
            binaryList.append(0)
    
    return binaryList
train_df['bin_ingredients']=train_df['ingredients'].apply(lambda x: binary(x))

train.head()

from scipy import spatial

def Similarity(Id1, Id2):
    a = train_df.iloc[Id1]
    b = train_df.iloc[Id2]
    
    A = a['bin_ingredients']
    B = b['bin_ingredients']
    distance=spatial.distance.cosine(A,B)
    
    return distance, Id2

food=[]
for i in train_df.index:
    food.append(Similarity(1,i))

food

common_ingredients=sorted(food,key=lambda x: x[0])[1:10]

common_ingredients

indexes=[]
for i in range(len(common_ingredients)):
    indexes.append(common_ingredients[i][1])
train_df.iloc[indexes]

import nltk

from collections import Counter

from sklearn.feature_extraction.text import TfidfVectorizer

vect = TfidfVectorizer(binary=True).fit(train_df['seperated_ingredients'].values)
X_train_vectorized = vect.transform(train_df['seperated_ingredients'].values)
X_train_vectorized = X_train_vectorized.astype('float')
Result_transformed = vect.transform(test_df['seperated_ingredients'].values)
Result_transformed = Result_transformed.astype('float')

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
y_transformed = encoder.fit_transform(train_df.cuisine)

y_transformed

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_train_vectorized, y_transformed , random_state = 0)

from sklearn.linear_model import LogisticRegression

clf1 = LogisticRegression(C=10,dual=False)
clf1.fit(X_train , y_train)
clf1.score(X_test, y_test)

from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
vclf=VotingClassifier(estimators=[('clf1',LogisticRegression(C=10,dual=False)),('clf2',SVC(C=100,gamma=1,kernel='rbf',probability=True))],voting='soft',weights=[1,2])
vclf.fit(X_train , y_train)
vclf.score(X_test, y_test)

y_predicted = clf1.predict(Result_transformed)
y_predicted_final = encoder.inverse_transform(y_predicted)
predictions = pd.DataFrame({'cuisine' : y_predicted_final , 'id' : test_df.id })
predictions = predictions[[ 'id' , 'cuisine']]
predictions.to_csv('submit.csv', index = False)